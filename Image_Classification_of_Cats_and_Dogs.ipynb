{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Image Classification of Cats and Dogs.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMnDCqo-AlIB",
        "colab_type": "code",
        "outputId": "3662dfe4-8c79-4c58-a9ab-62603ef18f0d",
        "colab": {}
      },
      "source": [
        "#Importing the keras libraries and packages\n",
        "\n",
        "from keras.models import Sequential  \n",
        "#Sequential package - to initialse the neural network. \n",
        "from keras.layers import Convolution2D \n",
        "#package we use to make convolutional layers. Since images are in 2D, we use convolution 2D\n",
        "from keras.layers import MaxPooling2D\n",
        "#To proceed to pooling step2\n",
        "from keras.layers import Flatten\n",
        "#to proceed to step3\n",
        "from keras.layers import Dense\n",
        "#we use it to add the fully connected layers to a ANN"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzHz-l5HAlIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialising the CNN\n",
        "classifier = Sequential() # an object of the sequential class"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTs-HCgkAlIi",
        "colab_type": "code",
        "outputId": "8a639b25-194d-49e3-8287-6f008a6e6721",
        "colab": {}
      },
      "source": [
        "# Step 1 - Convolution : Adding the first layer - Convolutional layer with the feature maps\n",
        "classifier.add(Convolution2D(filters=32, kernel_size=(3, 3), input_shape = (64, 64, 3), activation = 'relu',strides=(1, 1), padding='valid'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From E:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1S0rEvE2AlIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 2 - Pooling \n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ReaOdPmAlIz",
        "colab_type": "code",
        "outputId": "98423637-6693-4eb4-83da-babcf7e74100",
        "colab": {}
      },
      "source": [
        "#Adding 3 more convolutional layers and pooling layers inorder to improve accuracy and reduce the difference between the \n",
        "#acuracy on training and test set\n",
        "\n",
        "classifier.add(Convolution2D(32, 3, 3, activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "classifier.add(Convolution2D(32, 3, 3, activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "classifier.add(Convolution2D(32, 3, 3, activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
            "  after removing the cwd from sys.path.\n",
            "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
            "  import sys\n",
            "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOqsS88MAlJC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 3 - Flattening\n",
        "classifier.add(Flatten())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oaH-cAqAlJN",
        "colab_type": "code",
        "outputId": "9e0e6ee0-6fd6-40e3-deb0-cf3adef058aa",
        "colab": {}
      },
      "source": [
        "# Step 4 - Full connection\n",
        "classifier.add(Dense(output_dim = 128, activation = 'relu'))  #Creating a hidden layer and creating an output layer\n",
        "\n",
        "classifier.add(Dense(output_dim = 1, activation = 'sigmoid'))\n",
        "#Adding the output layer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
            "  \n",
            "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCzRJ5-iAlJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compiling the CNN\n",
        "\n",
        "classifier.compile(optimizer = 'sgd', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZpUY-HXAlJf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Part 2 - Fitting the CNN to the images\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45u_RssxAlJo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-4qypJdAlJ0",
        "colab_type": "code",
        "outputId": "f4ec9748-37f3-4c05-f804-ee3485752fcd",
        "colab": {}
      },
      "source": [
        "training_set = train_datagen.flow_from_directory('training_set',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gS-kTdTCAlJ7",
        "colab_type": "code",
        "outputId": "e4e24e6c-3e87-459c-a292-f5d2fcee9398",
        "colab": {}
      },
      "source": [
        "test_set = test_datagen.flow_from_directory('test_set',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83niB0gVAlKG",
        "colab_type": "code",
        "outputId": "07561f0c-ab44-449e-806e-541f421671bf",
        "colab": {}
      },
      "source": [
        "#classifier is the CNN model\n",
        "classifier.fit_generator(training_set,\n",
        "                         samples_per_epoch = 8000,\n",
        "                         nb_epoch = 25,\n",
        "                         validation_data = test_set,\n",
        "                         nb_val_samples = 2000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "  \n",
            "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=<keras_pre..., steps_per_epoch=250, epochs=25, validation_steps=2000)`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From E:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/25\n",
            "250/250 [==============================] - 834s 3s/step - loss: 0.6929 - acc: 0.5150 - val_loss: 0.6914 - val_acc: 0.5170\n",
            "Epoch 2/25\n",
            "250/250 [==============================] - 609s 2s/step - loss: 0.6911 - acc: 0.5311 - val_loss: 0.6900 - val_acc: 0.5777\n",
            "Epoch 3/25\n",
            "250/250 [==============================] - 565s 2s/step - loss: 0.6900 - acc: 0.5684 - val_loss: 0.6892 - val_acc: 0.5075\n",
            "Epoch 4/25\n",
            "250/250 [==============================] - 577s 2s/step - loss: 0.6885 - acc: 0.5569 - val_loss: 0.6863 - val_acc: 0.5921\n",
            "Epoch 5/25\n",
            "250/250 [==============================] - 592s 2s/step - loss: 0.6866 - acc: 0.5707 - val_loss: 0.6865 - val_acc: 0.5326\n",
            "Epoch 6/25\n",
            "250/250 [==============================] - 572s 2s/step - loss: 0.6851 - acc: 0.5714 - val_loss: 0.6822 - val_acc: 0.6026\n",
            "Epoch 7/25\n",
            "250/250 [==============================] - 588s 2s/step - loss: 0.6818 - acc: 0.5814 - val_loss: 0.6810 - val_acc: 0.5277\n",
            "Epoch 8/25\n",
            "250/250 [==============================] - 578s 2s/step - loss: 0.6799 - acc: 0.5757 - val_loss: 0.6810 - val_acc: 0.5215\n",
            "Epoch 9/25\n",
            "250/250 [==============================] - 555s 2s/step - loss: 0.6759 - acc: 0.5851 - val_loss: 0.6769 - val_acc: 0.5409\n",
            "Epoch 10/25\n",
            "250/250 [==============================] - 556s 2s/step - loss: 0.6735 - acc: 0.5859 - val_loss: 0.6630 - val_acc: 0.6238\n",
            "Epoch 11/25\n",
            "250/250 [==============================] - 556s 2s/step - loss: 0.6689 - acc: 0.5909 - val_loss: 0.6558 - val_acc: 0.6343\n",
            "Epoch 12/25\n",
            "250/250 [==============================] - 552s 2s/step - loss: 0.6669 - acc: 0.5948 - val_loss: 0.6666 - val_acc: 0.5790\n",
            "Epoch 13/25\n",
            "250/250 [==============================] - 566s 2s/step - loss: 0.6623 - acc: 0.6002 - val_loss: 0.6615 - val_acc: 0.5795\n",
            "Epoch 14/25\n",
            "250/250 [==============================] - 561s 2s/step - loss: 0.6610 - acc: 0.6029 - val_loss: 0.6445 - val_acc: 0.6508\n",
            "Epoch 15/25\n",
            "250/250 [==============================] - 560s 2s/step - loss: 0.6546 - acc: 0.6168 - val_loss: 0.6402 - val_acc: 0.6420\n",
            "Epoch 16/25\n",
            "250/250 [==============================] - 574s 2s/step - loss: 0.6513 - acc: 0.6199 - val_loss: 0.6361 - val_acc: 0.6531\n",
            "Epoch 17/25\n",
            "250/250 [==============================] - 565s 2s/step - loss: 0.6407 - acc: 0.6335 - val_loss: 0.6311 - val_acc: 0.6607\n",
            "Epoch 18/25\n",
            "250/250 [==============================] - 564s 2s/step - loss: 0.6418 - acc: 0.6360 - val_loss: 0.6251 - val_acc: 0.6571\n",
            "Epoch 19/25\n",
            "250/250 [==============================] - 559s 2s/step - loss: 0.6403 - acc: 0.6358 - val_loss: 0.6554 - val_acc: 0.6067\n",
            "Epoch 20/25\n",
            "250/250 [==============================] - 595s 2s/step - loss: 0.6305 - acc: 0.6454 - val_loss: 0.6312 - val_acc: 0.6420\n",
            "Epoch 21/25\n",
            "250/250 [==============================] - 671s 3s/step - loss: 0.6317 - acc: 0.6457 - val_loss: 0.6159 - val_acc: 0.6645\n",
            "Epoch 22/25\n",
            "250/250 [==============================] - 632s 3s/step - loss: 0.6252 - acc: 0.6481 - val_loss: 0.6447 - val_acc: 0.6350\n",
            "Epoch 23/25\n",
            "250/250 [==============================] - 558s 2s/step - loss: 0.6211 - acc: 0.6577 - val_loss: 0.6100 - val_acc: 0.6732\n",
            "Epoch 24/25\n",
            "250/250 [==============================] - 571s 2s/step - loss: 0.6201 - acc: 0.6576 - val_loss: 0.6065 - val_acc: 0.6715\n",
            "Epoch 25/25\n",
            "250/250 [==============================] - 588s 2s/step - loss: 0.6156 - acc: 0.6598 - val_loss: 0.6059 - val_acc: 0.6755\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1adbd484e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCruIhPAAlKP",
        "colab_type": "code",
        "outputId": "588a3c00-a51b-46c3-fb42-ab4dae365c92",
        "colab": {}
      },
      "source": [
        "#Testing the model\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('test_set/dogs/dog.4015.jpg', target_size = (64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = classifier.predict(test_image)\n",
        "training_set.class_indices\n",
        "if result[0][0] == 1:\n",
        "    prediction = 'dog'\n",
        "else:\n",
        "    prediction = 'cat'\n",
        "print(prediction)    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dog\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}